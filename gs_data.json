{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "WjUmtm0AAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Siyuan Zhou", "affiliation": "HKUST", "organization": 9568810911513724267, "interests": ["Computer Vision", "Robotics", "Reinforcement Learning"], "email_domain": "@connect.ust.hk", "homepage": "https://rainbow979.github.io/", "citedby": 344, "publications": {"WjUmtm0AAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Plasticinelab: A soft-body manipulation benchmark with differentiable physics", "pub_year": "2021"}, "filled": false, "author_pub_id": "WjUmtm0AAAAJ:u-x6o8ySG0sC", "num_citations": 137, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4373640289744241183", "cites_id": ["4373640289744241183"]}, "WjUmtm0AAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The threedworld transport challenge: A visually guided task-and-motion planning benchmark for physically realistic embodied ai", "pub_year": "2021"}, "filled": false, "author_pub_id": "WjUmtm0AAAAJ:d1gkVwhDpl0C", "num_citations": 82, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14990844153829331452,665398676336121775", "cites_id": ["14990844153829331452", "665398676336121775"]}, "WjUmtm0AAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Robodreamer: Learning compositional world models for robot imagination", "pub_year": "2024"}, "filled": false, "author_pub_id": "WjUmtm0AAAAJ:UebtZRa9Y70C", "num_citations": 41, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5676890862950279368,2895185546321203675", "cites_id": ["5676890862950279368", "2895185546321203675"]}, "WjUmtm0AAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adaptive online replanning with diffusion models", "pub_year": "2023"}, "filled": false, "author_pub_id": "WjUmtm0AAAAJ:_FxGoFyzp5QC", "num_citations": 26, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4541690294214833114", "cites_id": ["4541690294214833114"]}, "WjUmtm0AAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning task decomposition with ordered memory policy network", "pub_year": "2021"}, "filled": false, "author_pub_id": "WjUmtm0AAAAJ:u5HHmVD_uO8C", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=97140672639701123", "cites_id": ["97140672639701123"]}, "WjUmtm0AAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Finding fallen objects via asynchronous audio-visual integration", "pub_year": "2022"}, "filled": false, "author_pub_id": "WjUmtm0AAAAJ:W7OEmFMy1HYC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15481777873847697624", "cites_id": ["15481777873847697624"]}, "WjUmtm0AAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MA2QL: A minimalist approach to fully decentralized multi-agent reinforcement learning", "pub_year": "2022"}, "filled": false, "author_pub_id": "WjUmtm0AAAAJ:eQOLeE2rZwMC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1081376719699700253,337822407336099470", "cites_id": ["1081376719699700253", "337822407336099470"]}, "WjUmtm0AAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Adaworld: Learning adaptable world models with latent actions", "pub_year": "2025"}, "filled": false, "author_pub_id": "WjUmtm0AAAAJ:3fE2CSJIrl8C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12418753420478575316", "cites_id": ["12418753420478575316"]}, "WjUmtm0AAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TesserAct: learning 4D embodied world models", "pub_year": "2025"}, "filled": false, "author_pub_id": "WjUmtm0AAAAJ:MXK_kJrjxJIC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9404633825551768094,13102771892652624658", "cites_id": ["9404633825551768094", "13102771892652624658"]}, "WjUmtm0AAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning 3D Persistent Embodied World Models", "pub_year": "2025"}, "filled": false, "author_pub_id": "WjUmtm0AAAAJ:kNdYIx-mwKoC", "num_citations": 0}, "WjUmtm0AAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DCIR: Dynamic Consistency Intrinsic Reward for Multi-Agent Reinforcement Learning", "pub_year": "2023"}, "filled": false, "author_pub_id": "WjUmtm0AAAAJ:LkGwnXOMwfcC", "num_citations": 0}}, "citedby5y": 344, "hindex": 7, "hindex5y": 7, "i10index": 7, "i10index5y": 7, "cites_per_year": {"2021": 23, "2022": 49, "2023": 81, "2024": 124, "2025": 67}, "updated": "2025-06-05 08:12:07.187796"}